{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp base_model\n",
    "# default_cls_lvl 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model\n",
    "> Dieses Modul stellt die Wesentlichen Funktionen für Training, Prediction und Evaluation bereit. \n",
    "\n",
    "Nachdem wir nun die Daten nach Train und Testset aufgeteilt haben, geht es darum das Grundmodel zu definieren. Dieses werden wir wiederum Trainieren und evaluieren. Dazu werden wir auch die offizielle Formel für die Evaluation hernehmen und zwar Mean Average Precision. Der einzige Unterschied, wir evaluieren \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from pathlib import Path\n",
    "#from community_learning.features import target_cols\n",
    "from fastscript import *\n",
    "from tqdm import tqdm\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data(path_train='data/interim/03_train.csv',\n",
    "              path_test='data/interim/03_test.csv'):\n",
    "    \"\"\"load data\"\"\"\n",
    "    train = pd.read_csv(path_train)\n",
    "    test = pd.read_csv(path_test)\n",
    "    return (train, test)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org, test = load_data()\n",
    "train = train_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_shift_cols(columns:list):\n",
    "    \"\"\"get a list of columns\"\"\"\n",
    "    return [ col for col in columns if col[-2:] == '_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_cols = get_shift_cols(train.columns)\n",
    "assert len(shift_cols) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "feature_cols = ['ind_empleado', 'sexo', 'age', 'renta', 'ind_nuevo', \n",
    "                'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', \n",
    "                'conyuemp', 'indfall', 'tipodom', 'ind_actividad_cliente', \n",
    "                'segmento', 'antiguedad', 'pais_residencia', 'canal_entrada',\n",
    "                'ind_cco_fin_ult1_s', 'ind_cder_fin_ult1_s', 'ind_cno_fin_ult1_s',\n",
    "                'ind_ctju_fin_ult1_s', 'ind_ctma_fin_ult1_s', 'ind_ctop_fin_ult1_s',\n",
    "                'ind_ctpp_fin_ult1_s', 'ind_deco_fin_ult1_s', 'ind_deme_fin_ult1_s',\n",
    "                'ind_dela_fin_ult1_s', 'ind_ecue_fin_ult1_s', 'ind_fond_fin_ult1_s',\n",
    "                'ind_hip_fin_ult1_s', 'ind_plan_fin_ult1_s', 'ind_pres_fin_ult1_s',\n",
    "                'ind_reca_fin_ult1_s', 'ind_tjcr_fin_ult1_s', 'ind_valo_fin_ult1_s',\n",
    "                'ind_viv_fin_ult1_s', 'ind_nomina_ult1_s', 'ind_nom_pens_ult1_s',\n",
    "                'ind_recibo_ult1_s']\n",
    "\n",
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1',\n",
    "               'ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1',\n",
    "               'ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1',\n",
    "               'ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1',\n",
    "               'ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1',\n",
    "               'ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1',\n",
    "               'ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1',\n",
    "               'ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "\n",
    "#feature_cols += get_shift_cols(train.columns) #add the shifted products as feature columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def get_product_dict(df:pd.DataFrame):\n",
    "    \"\"\"returns product_name: integer pairs\"\"\"\n",
    "    products = sorted(list(df['y'].unique()))\n",
    "    return { product : i for i, product in enumerate(products) }\n",
    "\n",
    "def get_product_reverse_dict(df:pd.DataFrame):\n",
    "    \"\"\"returns product_name: integer pairs\"\"\"\n",
    "    products = sorted(list(df['y'].unique()))\n",
    "    return { i : product for i, product in enumerate(products) }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind_cco_fin_ult1': 0,\n",
       " 'ind_cder_fin_ult1': 1,\n",
       " 'ind_cno_fin_ult1': 2,\n",
       " 'ind_ctju_fin_ult1': 3,\n",
       " 'ind_ctma_fin_ult1': 4,\n",
       " 'ind_ctop_fin_ult1': 5,\n",
       " 'ind_ctpp_fin_ult1': 6,\n",
       " 'ind_deco_fin_ult1': 7,\n",
       " 'ind_dela_fin_ult1': 8,\n",
       " 'ind_deme_fin_ult1': 9,\n",
       " 'ind_ecue_fin_ult1': 10,\n",
       " 'ind_fond_fin_ult1': 11,\n",
       " 'ind_hip_fin_ult1': 12,\n",
       " 'ind_nom_pens_ult1': 13,\n",
       " 'ind_nomina_ult1': 14,\n",
       " 'ind_plan_fin_ult1': 15,\n",
       " 'ind_pres_fin_ult1': 16,\n",
       " 'ind_reca_fin_ult1': 17,\n",
       " 'ind_recibo_ult1': 18,\n",
       " 'ind_tjcr_fin_ult1': 19,\n",
       " 'ind_valo_fin_ult1': 20,\n",
       " 'ind_viv_fin_ult1': 21}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dict = get_product_dict(train_org)\n",
    "product_reverse_dict = get_product_reverse_dict(train_org)\n",
    "assert all([True  if i == j else False for i, j in zip(product_dict.keys(), product_reverse_dict.values())])\n",
    "assert type(product_dict) == dict\n",
    "assert type(product_reverse_dict) == dict\n",
    "product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ind_cco_fin_ult1',\n",
       " 1: 'ind_cder_fin_ult1',\n",
       " 2: 'ind_cno_fin_ult1',\n",
       " 3: 'ind_ctju_fin_ult1',\n",
       " 4: 'ind_ctma_fin_ult1',\n",
       " 5: 'ind_ctop_fin_ult1',\n",
       " 6: 'ind_ctpp_fin_ult1',\n",
       " 7: 'ind_deco_fin_ult1',\n",
       " 8: 'ind_dela_fin_ult1',\n",
       " 9: 'ind_deme_fin_ult1',\n",
       " 10: 'ind_ecue_fin_ult1',\n",
       " 11: 'ind_fond_fin_ult1',\n",
       " 12: 'ind_hip_fin_ult1',\n",
       " 13: 'ind_nom_pens_ult1',\n",
       " 14: 'ind_nomina_ult1',\n",
       " 15: 'ind_plan_fin_ult1',\n",
       " 16: 'ind_pres_fin_ult1',\n",
       " 17: 'ind_reca_fin_ult1',\n",
       " 18: 'ind_recibo_ult1',\n",
       " 19: 'ind_tjcr_fin_ult1',\n",
       " 20: 'ind_valo_fin_ult1',\n",
       " 21: 'ind_viv_fin_ult1'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_reverse_dict(train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def encode_products(df:pd.DataFrame):\n",
    "    \"\"\"encode products with integer\"\"\"\n",
    "    product_dict = get_product_dict(df)\n",
    "    df['y'] = df['y'].map(lambda x: product_dict[x]).astype(np.int8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = encode_products(train_org)\n",
    "assert train['y'].dtype == np.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def x_y_split(df:pd.DataFrame):\n",
    "    \"\"\"returns 2 dataframes for X and Y variables\"\"\"\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = x_y_split(train)\n",
    "assert 'y' not in train_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.95 ms\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def runXGB(train_X, train_y, feature_cols, seed_val=0, use_gpu=False):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.05\n",
    "    param['max_depth'] = 8\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 22\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    if use_gpu:\n",
    "        param['gpu_id'] = 0\n",
    "        param['tree_method'] = 'gpu_hist'\n",
    "    num_rounds = 50\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X[feature_cols], label=train_y)\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataFrame'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a5ab3f3f850b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clf = HistGradientBoostingClassifier(max_iter=1, learning_rate=1.0,\n\u001b[0m\u001b[1;32m      2\u001b[0m     max_depth=8, random_state=0).fit([train_X, feature_cols],train_y)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CommunityLearning/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# time spent predicting X for gradient and hessians update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0macc_prediction_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_DTYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CommunityLearning/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    748\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CommunityLearning/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/miniconda3/envs/CommunityLearning/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(max_iter=1, learning_rate=1.0,\n",
    "...     max_depth=8, random_state=0).fit([train_X, feature_cols],train_y)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "#model = runXGB(train_X, train_y, feature_cols, use_gpu=True)\n",
    "#assert type(model) == xgb.core.Booster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Für die [Evaluierung](https://www.kaggle.com/c/santander-product-recommendation/overview/evaluation) wird der Mean Average Precision @ 7 (MAP@7) hergenommen. Die unten stehenden Formel haben wir uns von [jturkewitz](https://github.com/jturkewitz/SideProjects/blob/4c437b02d5e017636c84cc22eb3ff71f8eea1308/Kaggle/Santander_Prod/santander_prod.py#L272) ausgeliehen. [Hier](http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html) noch eine gute Erklärung. \n",
    "\n",
    "$$\n",
    "MAP@7 =  \\dfrac{1} {\\vert U \\vert} \\sum^{\\vert U \\vert}_{u=1} \\dfrac {1} {min(m,7)} \\sum^{min(n,7)}_{k=1} P(k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.91 ms\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def apk(actual, predicted, k=7):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [ind_recibo_ult1, ind_tjcr_fin_ult1, ind_fond_...\n",
       "1         [ind_cco_fin_ult1, ind_dela_fin_ult1, ind_reca...\n",
       "2         [ind_nom_pens_ult1, ind_nomina_ult1, ind_ctop_...\n",
       "3         [ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...\n",
       "4         [ind_cno_fin_ult1, ind_fond_fin_ult1, ind_valo...\n",
       "                                ...                        \n",
       "702430    [ind_nom_pens_ult1, ind_nomina_ult1, ind_recib...\n",
       "702431    [ind_recibo_ult1, ind_nomina_ult1, ind_nom_pen...\n",
       "702432    [ind_recibo_ult1, ind_nomina_ult1, ind_cno_fin...\n",
       "702433    [ind_cco_fin_ult1, ind_recibo_ult1, ind_ecue_f...\n",
       "702434    [ind_recibo_ult1, ind_cno_fin_ult1, ind_nomina...\n",
       "Name: added_products, Length: 702435, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "xgtest = xgb.DMatrix(test[feature_cols])\n",
    "preds = model.predict(xgtest)\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:,:7]\n",
    "preds = pd.DataFrame(preds)\n",
    "preds = preds.applymap(lambda x: product_reverse_dict[x])\n",
    "preds['added_products'] = preds.apply(lambda x: list(x.values), axis=1)\n",
    "preds = preds['added_products']\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added_products</th>\n",
       "      <th>truth_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ind_recibo_ult1, ind_tjcr_fin_ult1, ind_fond_...</td>\n",
       "      <td>[ind_tjcr_fin_ult1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_dela_fin_ult1, ind_reca...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ind_nom_pens_ult1, ind_nomina_ult1, ind_ctop_...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ind_cno_fin_ult1, ind_fond_fin_ult1, ind_valo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702430</th>\n",
       "      <td>[ind_nom_pens_ult1, ind_nomina_ult1, ind_recib...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702431</th>\n",
       "      <td>[ind_recibo_ult1, ind_nomina_ult1, ind_nom_pen...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702432</th>\n",
       "      <td>[ind_recibo_ult1, ind_nomina_ult1, ind_cno_fin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702433</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_recibo_ult1, ind_ecue_f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702434</th>\n",
       "      <td>[ind_recibo_ult1, ind_cno_fin_ult1, ind_nomina...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702435 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           added_products           truth_list\n",
       "0       [ind_recibo_ult1, ind_tjcr_fin_ult1, ind_fond_...  [ind_tjcr_fin_ult1]\n",
       "1       [ind_cco_fin_ult1, ind_dela_fin_ult1, ind_reca...                   []\n",
       "2       [ind_nom_pens_ult1, ind_nomina_ult1, ind_ctop_...                   []\n",
       "3       [ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...                   []\n",
       "4       [ind_cno_fin_ult1, ind_fond_fin_ult1, ind_valo...                   []\n",
       "...                                                   ...                  ...\n",
       "702430  [ind_nom_pens_ult1, ind_nomina_ult1, ind_recib...                   []\n",
       "702431  [ind_recibo_ult1, ind_nomina_ult1, ind_nom_pen...                   []\n",
       "702432  [ind_recibo_ult1, ind_nomina_ult1, ind_cno_fin...                   []\n",
       "702433  [ind_cco_fin_ult1, ind_recibo_ult1, ind_ecue_f...                   []\n",
       "702434  [ind_recibo_ult1, ind_cno_fin_ult1, ind_nomina...                   []\n",
       "\n",
       "[702435 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "test['added_products'] = preds\n",
    "test['truth_list'] = test[target_cols].apply(lambda x: list(compress(target_cols, x.values)), axis=1)\n",
    "test[['added_products', 'truth_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean average precision = 0.022998457293851166\n",
      "time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "test['apk'] = test.apply(lambda x: apk(x['truth_list'], x['added_products']),axis=1)\n",
    "print(f\"mean average precision = {test['apk'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added_products</th>\n",
       "      <th>truth_list</th>\n",
       "      <th>apk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ind_recibo_ult1, ind_tjcr_fin_ult1, ind_fond_...</td>\n",
       "      <td>[ind_tjcr_fin_ult1]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_dela_fin_ult1, ind_reca...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ind_nom_pens_ult1, ind_nomina_ult1, ind_ctop_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ind_cno_fin_ult1, ind_fond_fin_ult1, ind_valo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[ind_tjcr_fin_ult1, ind_ecue_fin_ult1, ind_rec...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[ind_nom_pens_ult1, ind_nomina_ult1, ind_cno_f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[ind_cno_fin_ult1, ind_valo_fin_ult1, ind_ctop...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[ind_tjcr_fin_ult1, ind_nom_pens_ult1, ind_nom...</td>\n",
       "      <td>[ind_tjcr_fin_ult1]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       added_products           truth_list  \\\n",
       "0   [ind_recibo_ult1, ind_tjcr_fin_ult1, ind_fond_...  [ind_tjcr_fin_ult1]   \n",
       "1   [ind_cco_fin_ult1, ind_dela_fin_ult1, ind_reca...                   []   \n",
       "2   [ind_nom_pens_ult1, ind_nomina_ult1, ind_ctop_...                   []   \n",
       "3   [ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...                   []   \n",
       "4   [ind_cno_fin_ult1, ind_fond_fin_ult1, ind_valo...                   []   \n",
       "..                                                ...                  ...   \n",
       "95  [ind_cco_fin_ult1, ind_tjcr_fin_ult1, ind_reci...                   []   \n",
       "96  [ind_tjcr_fin_ult1, ind_ecue_fin_ult1, ind_rec...                   []   \n",
       "97  [ind_nom_pens_ult1, ind_nomina_ult1, ind_cno_f...                   []   \n",
       "98  [ind_cno_fin_ult1, ind_valo_fin_ult1, ind_ctop...                   []   \n",
       "99  [ind_tjcr_fin_ult1, ind_nom_pens_ult1, ind_nom...  [ind_tjcr_fin_ult1]   \n",
       "\n",
       "    apk  \n",
       "0   0.5  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "..  ...  \n",
       "95  0.0  \n",
       "96  0.0  \n",
       "97  0.0  \n",
       "98  0.0  \n",
       "99  1.0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.4 ms\n"
     ]
    }
   ],
   "source": [
    "test[['added_products', 'truth_list', 'apk']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.17 ms\n"
     ]
    }
   ],
   "source": [
    "#export \n",
    "def get_results(test_data:pd.DataFrame, \n",
    "                model:xgb.core.Booster,  \n",
    "                product_reverse_dict:list,\n",
    "                feature_cols:list=feature_cols,\n",
    "                target_cols:list=target_cols):\n",
    "    \"\"\"\"\"\"\n",
    "    xgtest = xgb.DMatrix(test_data[feature_cols])\n",
    "    preds = model.predict(xgtest)\n",
    "    preds = np.argsort(preds, axis=1)\n",
    "    preds = np.fliplr(preds)[:,:7]\n",
    "    preds = pd.DataFrame(preds)\n",
    "    preds = preds.applymap(lambda x: product_reverse_dict[x])\n",
    "    preds['added_products'] = preds.apply(lambda x: list(x.values), axis=1)\n",
    "    preds = preds['added_products']\n",
    "    \n",
    "    \n",
    "    test_data.reset_index(inplace=True)\n",
    "    test_data['added_products'] = preds\n",
    "    test_data['truth_list'] = test_data[target_cols].apply(lambda x: list(compress(target_cols, x.values)), axis=1)\n",
    "    test_data['apk'] = test_data.apply(lambda x: apk(x['truth_list'], x['added_products']),axis=1)\n",
    "    print(f\"mean average precision = {test_data['apk'].mean()}\")\n",
    "    return test_data[['id', 'added_products', 'truth_list', 'apk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean average precision = 0.003241901668357498\n",
      "time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "results = get_results(test, model, target_cols)\n",
    "assert 'id' in results\n",
    "assert 'truth_list' in results\n",
    "assert 'apk' in results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def get_base_model_results(source_train:Param(\"source csv file for train\", str)='data/interim/03_train.csv',\n",
    "                           source_test:Param(\"source csv file for test\", str)='data/interim/03_test.csv',\n",
    "                           dest:Param(\"destination csv file for the results\", str)='data/results/base_model.csv',\n",
    "                           feature_cols:Param(\"list of features to use for training\", str)=feature_cols):\n",
    "    \"\"\"\"\"\"\n",
    "    train_org, test = load_data(source_train, source_test)\n",
    "    \n",
    "    product_dict = get_product_dict(train_org)\n",
    "    product_reverse_dict = get_product_reverse_dict(train_org)    \n",
    "    \n",
    "    train = encode_products(train_org)\n",
    "    \n",
    "    train_X, train_y = x_y_split(train)\n",
    "    \n",
    "    model = runXGB(train_X, train_y, feature_cols, use_gpu=True)\n",
    "    \n",
    "    results = get_results(test, model, product_reverse_dict)\n",
    "    \n",
    "    results.to_csv(dest, index=False)\n",
    "    \n",
    "    path_model = Path(dest)\n",
    "    path_model = path_model.parent / (path_model.stem + '.dat')\n",
    "    pickle.dump(model, open(str(path_model), \"wb\"))\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean average precision = 0.022998457293851166\n",
      "mean average precision = 0.021781347503090444\n",
      "mean average precision = 0.020448746429794492\n",
      "time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "result1 = get_base_model_results(source_train='data/interim/03_train.csv',\n",
    "                                source_test='data/interim/03_test.csv',\n",
    "                                dest='data/results/04_shift.csv')\n",
    "result12 = get_base_model_results(source_train='data/interim/03_train_shift6.csv',\n",
    "                                source_test='data/interim/03_test_shift6.csv',\n",
    "                                dest='data/results/04_shift6.csv')\n",
    "result12 = get_base_model_results(source_train='data/interim/03_train_shift12.csv',\n",
    "                                source_test='data/interim/03_test_shift12.csv',\n",
    "                                dest='data/results/04_shift12.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "Wie wir sehen ist unser initiales Resultat soweit ok. Leider können wir diese Zahl nicht direkt mit derjenigen von der Kaggle Competition vergleichen, da wir eine andere Periode vorhersagen. Zudem haben wir viele mögliche Features aussen vor gelassen. In einem echten Szenario würde wir vor allem noch mehr Datasets generieren und mit verschiedenen Lags und Features testen. Als Baseline für dieses Experiment ist das Model in Ordnung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_data_preprocess.ipynb.\n",
      "Converted 02_data_Cleaning.ipynb.\n",
      "Converted 03_features.ipynb.\n",
      "Converted 04_base_model.ipynb.\n",
      "Converted 05_community_learning.ipynb.\n",
      "Converted 06_LightGBM_Federated_Learning.ipynb.\n",
      "Converted 06_XGBoost_Federated_Learning.ipynb.\n",
      "Converted 06_lightGBM.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n",
      "time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.42 ms\n"
     ]
    }
   ],
   "source": [
    "#!python community_learning/base_model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
