{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Learning\n",
    "\n",
    "> Ziel ist es mit diesem kleine PoC aufzuzeigen wie mit Hilfe von Federated Learning bessere Prognose erzielt werden können. \n",
    "Um den Nutzen aufzuzeigen nutzen wir die Beispieldaten von der Kaggle [Santander Product Recommendation](https://www.kaggle.com/c/santander-product-recommendation/data) Competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ein Auszug von der Kaggle Website\n",
    "\n",
    ">In this competition, you are provided with 1.5 years of customers behavior data from Santander bank to predict what new products customers will purchase. The data starts at 2015-01-28 and has monthly records of products a customer has, such as \"credit card\", \"savings account\", etc. You will predict what additional products a customer will get in the last month, 2016-06-28, in addition to what they already have at 2016-05-28. These products are the columns named: ind_(xyz)_ult1, which are the columns #25 - #48 in the training data. You will predict what a customer will buy in addition to what they already had at 2016-05-28. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Problem\n",
    "Wie weiter oben beschrieben ist das Ziel die zusätzlich gekauften Produkte im Monat vom 2016-06-28 zu bestimmen. Die Daten beinhalten Montasdaten von 2015-01-28 - 2016-05-28 (ca. 1.5 Jahre). Nun gäbe es mehrere Möglichkeiten das ML Problem zu formulieren: \n",
    "- wir versuchen immer die gekauften Produkte des nächsten Monats zu bestimmen\n",
    "- wir versuchen immer die gekauften Produkte für den Juni jeweils anhand des Vormonats zu bestimmen (ignorieren alle anderen Monate). \n",
    "- wir trainieren ein recommender system (collaborative filtering) mit allen Daten der Produkte und versuchen den letzten Monat vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorgehen PoC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Usecase möglichst realistisch zu gestalten, gehen wir wie folgt vor:\n",
    "\n",
    "\n",
    "**Variante 1:**\n",
    "1. **Daten bereitstellen und bereinigen**: Hierzu werden wir das Datenset so aufteilen, dass je ein Datenset pro Bank entsteht. Dazu werden wir ein geografisches Attribut hernehmen. Danach werden die Daten nochmals im Verhältnis 80/20 aufgeteilt in ein Train- und Testset (`data_bank1_train`, `data_bank1_test`, `data_bank2_train`, `data_bank2_test`). \n",
    "2. **Baseline Modelle trainiern:** Pro Bank werden wir einen GradientBoost Algorithmus trainieren mit deren Default-Einstellungen. Dadurch erhaltne wir 2 Modelle (`model_bank1` und `model_bank2`)\n",
    "3. **Ensemble Predictions:** In diesem Schritt werden wir die Resultate von model_bank1 und model_bank2 kombinieren. \n",
    " - `model_bank1` und `model_bank2` wird mit den `data_bank1_test` gefüttert und eine gemeinsame Prediction erstellt.\n",
    " - `model_bank1` und `model_bank2` wird mit den `data_bank2_test` gefüttert und eine gemeinsame Prediction erstellt.\n",
    "4. **Auswertung:**: Um festzustellen ob das Ensemble eine Mehrwert bringt werden folgende Resultate verglichen.\n",
    " - `model_bank1(data_bank1_test)` vs `ensemble(model_bank1(data_bank1_test), model_bank2(data_bank1_test)`\n",
    " - `model_bank2(data_bank2_test)` vs `ensemble(mdoel_bank2(data_bank1_test), model_bank2(data_bank2_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
