{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "> Dieses Modul werden die Daten runtergeladen und für die Verarbeitung vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download und unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import gdown\n",
    "import pandas as pd\n",
    "from nbdev import export\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def download_santander_data():\n",
    "    \"\"\"downloads the data from gdrive to the data folder\"\"\"   \n",
    "    dest = Path('data/raw/train_ver2.csv.zip')\n",
    "    \n",
    "    #only download if file not already exists\n",
    "    if not dest.exists(): \n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        gdown.download(\n",
    "            'https://drive.google.com/uc?export=download&id=1H-dFcuqI99OkXAawsTMkmylBz3exNUgZ', \n",
    "            'data/raw/train_ver2.csv.zip',\n",
    "            quiet=False)\n",
    "    else:\n",
    "        print(f\"file {dest} already exists.\")\n",
    "        \n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1H-dFcuqI99OkXAawsTMkmylBz3exNUgZ\n",
      "To: /home/wilhelm/CommunityLearning/data/raw/train_ver2.csv.zip\n",
      "225MB [02:41, 1.39MB/s] \n"
     ]
    }
   ],
   "source": [
    "path_file = download_santander_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def unzip(path:[Path,str], dest:[Path,str]='.'):\n",
    "    \"\"\"unzips a given file\"\"\"\n",
    "    path = Path(path)\n",
    "    dest = path.parent / path.stem\n",
    "    \n",
    "    if not dest.exists():\n",
    "        with ZipFile(str(path), 'r') as zipObj:\n",
    "            zipObj.extractall(str(path.parent))\n",
    "            print(f'extracted to {path.parent / path.stem}')\n",
    "    else:\n",
    "        print(f\"file {dest} already exists!\")\n",
    "    \n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted to data/raw/train_ver2.csv\n"
     ]
    }
   ],
   "source": [
    "path_file = unzip(path_file, path_file.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean data\n",
    "Hierfür verwenden wir im Wesentlichen die Empfehlungen von [Alan Pryors Jupyter Notebook](https://www.kaggle.com/apryor6/detailed-cleaning-visualization-python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# laden der Daten in einen DataFrame\n",
    "class SandanderData:\n",
    "    \"\"\"class which handles the data in a pipline style\"\"\"\n",
    "    \n",
    "    def load_csv(self, path_file:[Path, str], limit_rows=None):\n",
    "        \"\"\"load csv file to a pandas df\"\"\"\n",
    "\n",
    "        if limit_rows is None:  \n",
    "            self.df = pd.read_csv(\n",
    "                path_file,\n",
    "                dtype={\n",
    "                    \"sexo\":str,\n",
    "                    \"ind_nuevo\":str,\n",
    "                    \"ult_fec_cli_1t\":str,\n",
    "                    \"indext\":str})\n",
    "\n",
    "        self.df = pd.read_csv(\n",
    "            path_file,\n",
    "            dtype={\n",
    "                \"sexo\":str,\n",
    "                \"ind_nuevo\":str,\n",
    "                \"ult_fec_cli_1t\":str,\n",
    "                \"indext\":str},\n",
    "            nrows=limit_rows\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def convert_dates(self):\n",
    "        \"\"\"converting the dates of the df\"\"\"\n",
    "        self.df[\"fecha_dato\"] = pd.to_datetime(self.df[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "        self.df[\"fecha_alta\"] = pd.to_datetime(self.df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def add_month_feature(self):\n",
    "        \"\"\"add buy month to the features\"\"\"\n",
    "        self.df[\"month\"] = pd.DatetimeIndex(self.df[\"fecha_dato\"]).month\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def add_age_feature(self):\n",
    "        \"\"\"add customer age feature\"\"\"\n",
    "        self.df[\"age\"]   = pd.to_numeric(self.df[\"age\"], errors=\"coerce\")\n",
    "        return self\n",
    "    \n",
    "    def clean_age(self):\n",
    "        \"\"\"clean age with NA small and big ages\"\"\"\n",
    "        self.df.loc[self.df.age < 18,\"age\"]  = (self.df.loc[(self.df.age >= 18) \n",
    "                                                       & (self.df.age <= 30),\"age\"].mean(skipna=True))\n",
    "        self.df.loc[self.df.age > 100,\"age\"] = (self.df.loc[(self.df.age >= 30) \n",
    "                                                       & (self.df.age <= 100),\"age\"].mean(skipna=True))\n",
    "        self.df[\"age\"].fillna(self.df[\"age\"].mean(),inplace=True)\n",
    "        self.df[\"age\"] = self.df[\"age\"].astype(int)\n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def clean_ind_nuevo(self):\n",
    "        \"\"\"ind_nuevo indicates a new customer. We replace missing values with one\"\"\"\n",
    "        self.df.loc[df[\"ind_nuevo\"].isnull(),\"ind_nuevo\"] = 1\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def clean_antiguedad(self):\n",
    "        \"\"\"antiguedad means senority. All missing antiguedad have the same NAs as the ind_nuevo.\"\"\"\n",
    "        self.df.antiguedad = pd.to_numeric(self.df.antiguedad,errors=\"coerce\")\n",
    "        self.df.loc[self.df.antiguedad.isnull(),\"antiguedad\"] = self.df.antiguedad.min()\n",
    "        self.df.loc[self.df.antiguedad < 0.0, \"antiguedad\"]  = 0 # Thanks @StephenSmith for bug-find\n",
    "        return self\n",
    "    \n",
    "    def replace_missing_dates_with_median(self):\n",
    "        \"\"\"replace missing fecha_alta with median dates\"\"\"\n",
    "        dates=data.df.loc[:,\"fecha_alta\"].sort_values().reset_index()\n",
    "        median_date = int(np.median(dates.index.values))\n",
    "        self.df.loc[self.df.fecha_alta.isnull(),\"fecha_alta\"] = dates.loc[median_date,\"fecha_alta\"]\n",
    "        return self\n",
    "    \n",
    "    def clean_indrel(self):\n",
    "        \"\"\"\n",
    "        indrel value of 1 indicates primary customer 99 means primary customer at the beginning \n",
    "        of the month but not end of the month\"\"\"\n",
    "        self.df.loc[self.df.indrel.isnull(),\"indrel\"] = 1\n",
    "        return self\n",
    "    \n",
    "    def drop_tipodom(self):\n",
    "        \"\"\"drop tipodom - Adres type\"\"\"\n",
    "        self.df.drop([\"tipodom\",\"cod_prov\"],axis=1,inplace=True)\n",
    "        return self\n",
    "    \n",
    "    def clean_ind_actividad_cliente(self):\n",
    "        \"\"\"we replace NANs with the median\"\"\"\n",
    "        self.df.loc[self.df.ind_actividad_cliente.isnull(),\"ind_actividad_cliente\"] = \\\n",
    "        self.df[\"ind_actividad_cliente\"].median()\n",
    "        return self\n",
    "    \n",
    "    def clean_nomprov(self):\n",
    "        \"\"\"remove special character and NANs\"\"\"\n",
    "        self.df.loc[self.df.nomprov==\"CORU\\xc3\\x91A, A\",\"nomprov\"] = \"CORUNA, A\"\n",
    "        self.df.loc[self.df.nomprov.isnull(),\"nomprov\"] = \"UNKNOWN\"\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def clean_renta(self):\n",
    "        \"\"\"fill in NaNs with median value from its region\"\"\"\n",
    "        grouped = df.groupby(\"nomprov\").agg({\"renta\":lambda x: x.median(skipna=True)}).reset_index()\n",
    "        new_incomes = pd.merge(df,grouped,how=\"inner\",on=\"nomprov\").loc[:, [\"nomprov\",\"renta_y\"]]\n",
    "        new_incomes = new_incomes.rename(columns={\"renta_y\":\"renta\"}).sort_values(\"renta\").sort_values(\"nomprov\")\n",
    "        df.sort_values(\"nomprov\",inplace=True)\n",
    "        df = df.reset_index()\n",
    "        new_incomes = new_incomes.reset_index()\n",
    "        \n",
    "        df.loc[df.renta.isnull(),\"renta\"] = new_incomes.loc[df.renta.isnull(),\"renta\"].reset_index()\n",
    "        df.loc[df.renta.isnull(),\"renta\"] = df.loc[df.renta.notnull(),\"renta\"].median()\n",
    "        df.sort_values(by=\"fecha_dato\",inplace=True)\n",
    "    \n",
    "               \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (SandanderData()\n",
    "        .load_csv(path_file, 10000)\n",
    "        .convert_dates()\n",
    "        .add_month_feature()\n",
    "        .add_age_feature()\n",
    "        .clean_age()\n",
    "        .clean_ind_nuevo()\n",
    "        .clean_antiguedad()\n",
    "        .replace_missing_dates_with_median()\n",
    "        .clean_indrel()\n",
    "        .drop_tipodom()\n",
    "        .clean_ind_actividad_cliente()\n",
    "        .clean_nomprov()\n",
    "       )\n",
    "\n",
    "\n",
    "#tests\n",
    "assert type(data.df) == pd.core.frame.DataFrame\n",
    "assert type(data) == SandanderData\n",
    "assert \"age\" in data.df.columns\n",
    "assert \"month\" in data.df.columns\n",
    "assert data.df.fecha_dato.dtype == '<M8[ns]'\n",
    "assert data.df.fecha_alta.dtype == '<M8[ns]'\n",
    "assert data.df.age.isnull().any() == False, \"found NAs in dataset\"\n",
    "assert data.df.age.min() >= 18\n",
    "assert data.df.age.max() <= 100\n",
    "assert data.df.age.dtype == 'int'\n",
    "assert data.df.ind_nuevo.isnull().any() == False\n",
    "assert data.df.antiguedad.isnull().any() == False\n",
    "assert data.df.antiguedad.min() >= 0\n",
    "assert data.df.fecha_alta.isnull().any() == False\n",
    "assert data.df.indrel.isnull().any() == False\n",
    "assert \"tipodom\" not in data.df.columns\n",
    "assert data.df[\"ind_actividad_cliente\"].isnull().any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data_prep.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
